{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, hidden_layers,dropout):\n",
    "        hidden_layers.insert(0,77)\n",
    "        hidden_layers.append(1)\n",
    "        self.layers=hidden_layers\n",
    "        self.L=len(hidden_layers)\n",
    "        print(self.L)\n",
    "        \n",
    "        #self.beta={}\n",
    "        #self.gamma={}\n",
    "        self.W={}\n",
    "        self.b={}\n",
    "        \n",
    "        self.keepprob={}\n",
    "        \n",
    "        #self.dbeta={}\n",
    "        #self.dgamma={}\n",
    "        self.dW={}\n",
    "        self.db={}\n",
    "        self.initialize_parameters(dropout)\n",
    "        \n",
    "    def initialize_parameters(self, dropout):\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            #self.beta[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            #self.gamma[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            self.keepprob[i]=tf.Variable(dropout)\n",
    "            \n",
    "    def forward_pass(self,A, mode=\"train\"):\n",
    "        for i in range(1, self.L):\n",
    "            if mode==\"train\":\n",
    "                A = tf.nn.dropout(A, self.keepprob[i])\n",
    "            Z=tf.matmul(self.W[i],A)+self.b[i]\n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "            else:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self,Yhat,Y):\n",
    "        cost=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Yhat, Y))) #root mean square error cost function\n",
    "        return cost\n",
    "    \n",
    "    def evaluate_rmse(self, predicted, Y):\n",
    "        rmse=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(predicted, Y))) #root mean square error cost function\n",
    "        return rmse\n",
    "    \n",
    "    def update_parameters(self,learning_rate, normalization_lr):\n",
    "            for i in range(1,self.L):\n",
    "                self.W[i].assign_sub(learning_rate*self.dW[i])\n",
    "                self.b[i].assign_sub(learning_rate*self.db[i])\n",
    "                #self.beta[i].assign_sub(normalization_lr*self.dbeta[i])\n",
    "                #self.gamma[i].assign_sub(normalization_lr*self.dgamma[i])\n",
    "    \n",
    "    def train(self,X,Y, learning_rate, decay_rate, normalization_lr, iterations):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y=tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "        for i in range(iterations+1):\n",
    "            with tf.GradientTape(persistent=True) as g:\n",
    "                Yhat=self.forward_pass(X)\n",
    "                cost=self.compute_cost(Yhat,Y)\n",
    "                \n",
    "            for j in range(1,self.L):\n",
    "                self.dW[j]=g.gradient(cost, self.W[j])\n",
    "                self.db[j]=g.gradient(cost, self.b[j])\n",
    "                #self.dbeta[j]=g.gradient(cost, self.beta[j])\n",
    "                #self.dgamma[j]=g.gradient(cost,self.gamma[j])\n",
    "                \n",
    "            del g\n",
    "            \n",
    "            learning_rate=learning_rate/(1+decay_rate*i)\n",
    "            \n",
    "            self.update_parameters(learning_rate, normalization_lr)\n",
    "            if (i%100==0):\n",
    "                print(\"Error on iteration {} is: \".format(i), cost.numpy())\n",
    "    \n",
    "    def upload_parameters(self,W,b,beta,gamma):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.beta=beta\n",
    "        self.gamma=gamma\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        prediction=self.forward_pass(X, mode=\"test\")\n",
    "        return prediction\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#первый датасет Доры\n",
    "X_train = pd.read_csv('nonorm_negignore_knn3/x_knn_train_negative.csv', header=0).values[:, 1:].T\n",
    "Y_train = pd.read_csv('nonorm_negignore_knn3/y_knn_train_negative.csv', header=0).values[:, 1:].T\n",
    "X_test = pd.read_csv('nonorm_negignore_knn3/x_knn_test_negative.csv', header=0).values[:, 1:].T\n",
    "Y_test = pd.read_csv('nonorm_negignore_knn3/y_knn_test_negative.csv', header=0).values[:, 1:].T\n",
    "\n",
    "#второй датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3/x_knn_train_negative_normalized.csv', header=0).values[:, 1:].T\n",
    "Y_train = pd.read_csv('norm_negignore_knn3/y_knn_train_negative_normalized.csv', header=0).values[:, 1:].T\n",
    "X_test = pd.read_csv('norm_negignore_knn3/x_knn_test_negative_normalized.csv', header=0).values[:, 1:].T\n",
    "Y_test = pd.read_csv('norm_negignore_knn3/y_knn_test_negative_normalized.csv', header=0).values[:, 1:].T\n",
    "\n",
    "#третий датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3+mean/x_train_knn+mean.csv', header=0).values[:, 1:].T\n",
    "Y_train = pd.read_csv('norm_negignore_knn3+mean/y_train_knn+mean.csv', header=0).values[:, 1:].T\n",
    "X_test = pd.read_csv('norm_negignore_knn3+mean/x_test_knn+mean.csv', header=0).values[:, 1:].T\n",
    "Y_test = pd.read_csv('norm_negignore_knn3+mean/y_test_knn+mean.csv', header=0).values[:, 1:].T\n",
    "\"\"\"\n",
    "#интерполяция + knn\n",
    "X_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_train_knn+interpol.csv', header=0).values[:, 1:].T\n",
    "Y_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_train_knn+interpol.csv', header=0).values[:, 1:].T\n",
    "X_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_test_knn+interpol.csv', header=0).values[:, 1:].T\n",
    "Y_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_test_knn+interpol.csv', header=0).values[:, 1:].T\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#цифры на шару\n",
    "hidden_layers=[128,320,320,20] #кол-во элементов это кол-во hidden layers, значение элемента это кол-во neurons в этом layer\n",
    "learning_rate=0.001\n",
    "decay_rate=0.001\n",
    "dropout=0.6\n",
    "normalization_lr=0.001\n",
    "\n",
    "iterations=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=NN(hidden_layers,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.train(X_train, Y_train, learning_rate, decay_rate, normalization_lr, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_train=network.predict(X_train)\n",
    "error_train=network.evaluate_rmse(predictions_train,Y_train)\n",
    "\n",
    "predictions_test=network.predict(X_test)\n",
    "error_test=network.evaluate_rmse(predictions_test,Y_test)\n",
    "\n",
    "print(\"Average error on train set: \", error_train.numpy())\n",
    "print(\"Average error on test set: \", error_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=tf.Variable(tf.random.normal(shape=(3,5)))\n",
    "a=tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "print(a)\n",
    "a, norm=tf.linalg.normalize(a, axis=1)\n",
    "print(a)\n",
    "print(norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
