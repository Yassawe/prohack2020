{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yassawe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, hidden_layers):\n",
    "        hidden_layers.insert(0,77)\n",
    "        hidden_layers.append(1)\n",
    "        self.layers=hidden_layers\n",
    "        self.L=len(hidden_layers)\n",
    "        #self.beta={}\n",
    "        #self.gamma={}\n",
    "        self.W={}\n",
    "        self.b={}\n",
    "        self.keepprob={}\n",
    "        self.initialize_parameters()\n",
    "     \n",
    "    def placeholders(self):\n",
    "        X=tf.placeholder(tf.float32, shape=(None, 77), name=\"X\")\n",
    "        Y=tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
    "        return X,Y\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            self.keepprob[i]=tf.Variable(0.8)\n",
    "            #self.beta[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            #self.gamma[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            \n",
    "    def forward_pass(self,A, mode=\"train\"):\n",
    "        for i in range(1, self.L):\n",
    "            if mode==\"train\":\n",
    "                A = tf.nn.dropout(A, self.keepprob[i]) \n",
    "            \n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i]))+tf.transpose(self.b[i])\n",
    "            \n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "            else:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self,Yhat,Y):\n",
    "        cost=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Yhat, Y)))\n",
    "        return cost\n",
    "    \n",
    "    def evaluate_rmse(self, predicted, Y):\n",
    "        rmse=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(predicted, Y))) #root mean square error cost function\n",
    "        return rmse\n",
    "    \n",
    "    def train(self, X_train,Y_train, learning_rate, iterations, sess):\n",
    "        X,Y=self.placeholders()\n",
    "        Yhat=self.forward_pass(X)\n",
    "        cost=self.compute_cost(Yhat, Y)\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.5, staircase=True)\n",
    "        trainer = tf.train.AdamOptimizer(decayed_lr, epsilon=1e-10).minimize(cost)\n",
    "        init=tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for i in range(iterations):\n",
    "            _ ,temp_cost=sess.run([trainer, cost], feed_dict={X:X_train, Y:Y_train})\n",
    "            if i%100==0:\n",
    "                print(\"Cost on iteration {} :\".format(i), temp_cost)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        prediction=self.forward_pass(X, \"test\")\n",
    "        return prediction\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2610, 77)\n",
      "(2610, 1)\n",
      "(1255, 77)\n",
      "(1255, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#первый датасет Доры\n",
    "X_train = pd.read_csv('nonorm_negignore_knn3/x_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('nonorm_negignore_knn3/y_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('nonorm_negignore_knn3/x_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('nonorm_negignore_knn3/y_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "\n",
    "#второй датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3/x_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3/y_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3/x_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3/y_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "\n",
    "#третий датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3+mean/x_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3+mean/y_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3+mean/x_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3+mean/y_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "\n",
    "\n",
    "#интерполяция + knn\n",
    "X_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "\n",
    "\"\"\"\n",
    "X_train = pd.read_csv('datasets/iterative_imputer/x_train_iter+knn+time.csv', header=0).values[:, 3:]\n",
    "Y_train = pd.read_csv('datasets/iterative_imputer/y_train_iter+knn+time.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('datasets/iterative_imputer/x_test_iter+knn+time.csv', header=0).values[:, 3:]\n",
    "Y_test = pd.read_csv('datasets/iterative_imputer/y_test_iter+knn+time.csv', header=0).values[:, 1:]\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers=[128, 320, 320, 50, 20, 1] #кол-во элементов это кол-во hidden layers, значение элемента это кол-во neurons в этом layer\n",
    "learning_rate=0.001\n",
    "iterations=10000\n",
    "dropout=0.9 #probability to keep nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "network=NN(hidden_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "#чтобы вытащить модель из сохранения\n",
    "#saver.restore(sess, 'prohack_tf_savedmodel/saved_variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on iteration 0 : 0.43835688\n",
      "Cost on iteration 100 : 0.41336742\n",
      "Cost on iteration 200 : 0.38867325\n",
      "Cost on iteration 300 : 0.36430043\n",
      "Cost on iteration 400 : 0.34043062\n",
      "Cost on iteration 500 : 0.31723723\n",
      "Cost on iteration 600 : 0.29486638\n",
      "Cost on iteration 700 : 0.273438\n",
      "Cost on iteration 800 : 0.25304356\n",
      "Cost on iteration 900 : 0.23374729\n",
      "Cost on iteration 1000 : 0.21559078\n",
      "Cost on iteration 1100 : 0.19859105\n",
      "Cost on iteration 1200 : 0.1827516\n",
      "Cost on iteration 1300 : 0.16806191\n",
      "Cost on iteration 1400 : 0.15450028\n",
      "Cost on iteration 1500 : 0.14203764\n",
      "Cost on iteration 1600 : 0.13064244\n",
      "Cost on iteration 1700 : 0.12027755\n",
      "Cost on iteration 1800 : 0.11090664\n",
      "Cost on iteration 1900 : 0.10249087\n",
      "Cost on iteration 2000 : 0.094990164\n",
      "Cost on iteration 2100 : 0.08836211\n",
      "Cost on iteration 2200 : 0.082561255\n",
      "Cost on iteration 2300 : 0.07753728\n",
      "Cost on iteration 2400 : 0.073234774\n",
      "Cost on iteration 2500 : 0.0695931\n",
      "Cost on iteration 2600 : 0.06654679\n",
      "Cost on iteration 2700 : 0.06402782\n",
      "Cost on iteration 2800 : 0.061967414\n",
      "Cost on iteration 2900 : 0.060299158\n",
      "Cost on iteration 3000 : 0.05896104\n",
      "Cost on iteration 3100 : 0.057896767\n",
      "Cost on iteration 3200 : 0.057056632\n",
      "Cost on iteration 3300 : 0.05639812\n",
      "Cost on iteration 3400 : 0.055885494\n",
      "Cost on iteration 3500 : 0.05548865\n",
      "Cost on iteration 3600 : 0.055183895\n",
      "Cost on iteration 3700 : 0.054951377\n",
      "Cost on iteration 3800 : 0.054775223\n",
      "Cost on iteration 3900 : 0.054642875\n",
      "Cost on iteration 4000 : 0.05454429\n",
      "Cost on iteration 4100 : 0.054471537\n",
      "Cost on iteration 4200 : 0.054418635\n",
      "Cost on iteration 4300 : 0.05438009\n",
      "Cost on iteration 4400 : 0.054352783\n",
      "Cost on iteration 4500 : 0.054333616\n",
      "Cost on iteration 4600 : 0.05432169\n",
      "Cost on iteration 4700 : 0.054311328\n",
      "Cost on iteration 4800 : 0.05430534\n",
      "Cost on iteration 4900 : 0.05430139\n",
      "Cost on iteration 5000 : 0.054298926\n",
      "Cost on iteration 5100 : 0.054297134\n",
      "Cost on iteration 5200 : 0.052406725\n",
      "Cost on iteration 5300 : 0.050860457\n",
      "Cost on iteration 5400 : 0.050166976\n",
      "Cost on iteration 5500 : 0.05016806\n",
      "Cost on iteration 5600 : 0.049505975\n",
      "Cost on iteration 5700 : 0.049402244\n",
      "Cost on iteration 5800 : 0.048903298\n",
      "Cost on iteration 5900 : 0.049135715\n",
      "Cost on iteration 6000 : 0.049393166\n",
      "Cost on iteration 6100 : 0.04934619\n",
      "Cost on iteration 6200 : 0.049187716\n",
      "Cost on iteration 6300 : 0.049004853\n",
      "Cost on iteration 6400 : 0.049400635\n",
      "Cost on iteration 6500 : 0.04942713\n",
      "Cost on iteration 6600 : 0.04898703\n",
      "Cost on iteration 6700 : 0.049453024\n",
      "Cost on iteration 6800 : 0.049372457\n",
      "Cost on iteration 6900 : 0.049113564\n",
      "Cost on iteration 7000 : 0.04907671\n",
      "Cost on iteration 7100 : 0.0494436\n",
      "Cost on iteration 7200 : 0.049240265\n",
      "Cost on iteration 7300 : 0.049371205\n",
      "Cost on iteration 7400 : 0.04954419\n",
      "Cost on iteration 7500 : 0.049609352\n",
      "Cost on iteration 7600 : 0.04966811\n",
      "Cost on iteration 7700 : 0.04957275\n",
      "Cost on iteration 7800 : 0.04957009\n",
      "Cost on iteration 7900 : 0.049329706\n",
      "Cost on iteration 8000 : 0.04910563\n",
      "Cost on iteration 8100 : 0.04943304\n",
      "Cost on iteration 8200 : 0.04967976\n",
      "Cost on iteration 8300 : 0.049727894\n",
      "Cost on iteration 8400 : 0.04963187\n",
      "Cost on iteration 8500 : 0.049538247\n",
      "Cost on iteration 8600 : 0.049541112\n",
      "Cost on iteration 8700 : 0.04978083\n",
      "Cost on iteration 8800 : 0.049877748\n",
      "Cost on iteration 8900 : 0.049583692\n",
      "Cost on iteration 9000 : 0.049468096\n",
      "Cost on iteration 9100 : 0.049750116\n",
      "Cost on iteration 9200 : 0.049583156\n",
      "Cost on iteration 9300 : 0.04997212\n",
      "Cost on iteration 9400 : 0.049832597\n",
      "Cost on iteration 9500 : 0.0497052\n",
      "Cost on iteration 9600 : 0.049428992\n",
      "Cost on iteration 9700 : 0.04986727\n",
      "Cost on iteration 9800 : 0.04996567\n",
      "Cost on iteration 9900 : 0.049725197\n"
     ]
    }
   ],
   "source": [
    "network.train(X_train, Y_train, learning_rate, iterations, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error on train set:  0.044448044\n",
      "Average error on test set:  0.069658816\n",
      "***********************\n",
      "predictions:  [[0.06695151]\n",
      " [0.06689611]\n",
      " [0.06684345]\n",
      " ...\n",
      " [0.09936765]\n",
      " [0.09936765]\n",
      " [0.09936765]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train=network.predict(X_train)\n",
    "error_train=network.evaluate_rmse(predictions_train,Y_train).eval()\n",
    "\n",
    "predictions_test=network.predict(X_test)\n",
    "error_test=network.evaluate_rmse(predictions_test,Y_test).eval()\n",
    "\n",
    "predictions_test=predictions_test.eval()\n",
    "    \n",
    "print(\"Average error on train set: \", error_train)\n",
    "print(\"Average error on test set: \", error_test)\n",
    "\n",
    "print(\"***********************\")\n",
    "print(\"predictions: \", predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#чтобы сохранить модель\n",
    "#saver.save(sess, 'saved models/addfolder/addfilename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(array of predictions).to_csv(\"file path\", header=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
