{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yassawe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, hidden_layers):\n",
    "        hidden_layers.insert(0,77)\n",
    "        hidden_layers.append(1)\n",
    "        self.layers=hidden_layers\n",
    "        self.L=len(hidden_layers)\n",
    "        #self.beta={}\n",
    "        #self.gamma={}\n",
    "        self.W={}\n",
    "        self.b={}\n",
    "        self.keepprob={}\n",
    "        self.initialize_parameters()\n",
    "     \n",
    "    def placeholders(self):\n",
    "        X=tf.placeholder(tf.float32, shape=(None, 77), name=\"X\")\n",
    "        Y=tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
    "        return X,Y\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            self.keepprob[i]=tf.Variable(0.8)\n",
    "            #self.beta[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            #self.gamma[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            \n",
    "    def forward_pass(self,A, mode=\"train\"):\n",
    "        for i in range(1, self.L):\n",
    "            if mode==\"train\":\n",
    "                A = tf.nn.dropout(A, self.keepprob[i]) \n",
    "            \n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i]))+tf.transpose(self.b[i])\n",
    "            \n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "            else:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self,Yhat,Y):\n",
    "        cost=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Yhat, Y)))\n",
    "        return cost\n",
    "    \n",
    "    def evaluate_rmse(self, predicted, Y):\n",
    "        rmse=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(predicted, Y))) #root mean square error cost function\n",
    "        return rmse\n",
    "    \n",
    "    def train(self, X_train,Y_train, learning_rate, iterations, sess):\n",
    "        X,Y=self.placeholders()\n",
    "        Yhat=self.forward_pass(X)\n",
    "        cost=self.compute_cost(Yhat, Y)\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.5, staircase=True)\n",
    "        trainer = tf.train.AdamOptimizer(decayed_lr, epsilon=1e-10).minimize(cost)\n",
    "        init=tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for i in range(iterations):\n",
    "            _ ,temp_cost=sess.run([trainer, cost], feed_dict={X:X_train, Y:Y_train})\n",
    "            if i%100==0:\n",
    "                print(\"Cost on iteration {} :\".format(i), temp_cost)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        prediction=self.forward_pass(X, \"test\")\n",
    "        return prediction\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(2532, 77)\n",
      "(2532, 1)\n",
      "(1333, 77)\n",
      "(1333, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#первый датасет Доры\n",
    "X_train = pd.read_csv('nonorm_negignore_knn3/x_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('nonorm_negignore_knn3/y_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('nonorm_negignore_knn3/x_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('nonorm_negignore_knn3/y_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "\n",
    "#второй датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3/x_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3/y_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3/x_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3/y_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "\n",
    "#третий датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3+mean/x_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3+mean/y_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3+mean/x_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3+mean/y_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "\n",
    "\n",
    "#интерполяция + knn\n",
    "X_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/x_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('datasets/norm_negignore_interpol_knn3/y_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "\n",
    "\"\"\"\n",
    "X_train = pd.read_csv('datasets/iterative_imputer/x_train.csv', header=0).values[:, 2:]\n",
    "Y_train = pd.read_csv('datasets/iterative_imputer/y_train.csv', header=0).values[:, :]\n",
    "X_test = pd.read_csv('datasets/iterative_imputer/x_test.csv', header=0).values[:, 2:]\n",
    "Y_test = pd.read_csv('datasets/iterative_imputer/y_test.csv', header=0).values[:, :]\n",
    "\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers=[128,320,20] #кол-во элементов это кол-во hidden layers, значение элемента это кол-во neurons в этом layer\n",
    "learning_rate=0.001\n",
    "iterations=10000\n",
    "dropout=0.9 #probability to keep nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "network=NN(hidden_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "#чтобы вытащить модель из сохранения\n",
    "#saver.restore(sess, 'prohack_tf_savedmodel/saved_variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-08ba99bd7b3c>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Cost on iteration 0 : 0.8204547\n",
      "Cost on iteration 100 : 0.10943946\n",
      "Cost on iteration 200 : 0.10064619\n",
      "Cost on iteration 300 : 0.09212632\n",
      "Cost on iteration 400 : 0.08725669\n",
      "Cost on iteration 500 : 0.07092679\n",
      "Cost on iteration 600 : 0.059998002\n",
      "Cost on iteration 700 : 0.05781811\n",
      "Cost on iteration 800 : 0.05473951\n",
      "Cost on iteration 900 : 0.05462234\n",
      "Cost on iteration 1000 : 0.053108197\n",
      "Cost on iteration 1100 : 0.051820323\n",
      "Cost on iteration 1200 : 0.05088073\n",
      "Cost on iteration 1300 : 0.04798931\n",
      "Cost on iteration 1400 : 0.047902133\n",
      "Cost on iteration 1500 : 0.046619937\n",
      "Cost on iteration 1600 : 0.047039244\n",
      "Cost on iteration 1700 : 0.044874385\n",
      "Cost on iteration 1800 : 0.044672977\n",
      "Cost on iteration 1900 : 0.044330057\n",
      "Cost on iteration 2000 : 0.0434616\n",
      "Cost on iteration 2100 : 0.043054774\n",
      "Cost on iteration 2200 : 0.043127246\n",
      "Cost on iteration 2300 : 0.041275512\n",
      "Cost on iteration 2400 : 0.040199246\n",
      "Cost on iteration 2500 : 0.037958544\n",
      "Cost on iteration 2600 : 0.037679847\n",
      "Cost on iteration 2700 : 0.037115324\n",
      "Cost on iteration 2800 : 0.036225602\n",
      "Cost on iteration 2900 : 0.035506353\n",
      "Cost on iteration 3000 : 0.035317913\n",
      "Cost on iteration 3100 : 0.035788167\n",
      "Cost on iteration 3200 : 0.034425713\n",
      "Cost on iteration 3300 : 0.03501957\n",
      "Cost on iteration 3400 : 0.034119386\n",
      "Cost on iteration 3500 : 0.035832588\n",
      "Cost on iteration 3600 : 0.034291536\n",
      "Cost on iteration 3700 : 0.03342018\n",
      "Cost on iteration 3800 : 0.034332123\n",
      "Cost on iteration 3900 : 0.033560913\n",
      "Cost on iteration 4000 : 0.03242201\n",
      "Cost on iteration 4100 : 0.032838438\n",
      "Cost on iteration 4200 : 0.03299664\n",
      "Cost on iteration 4300 : 0.031502686\n",
      "Cost on iteration 4400 : 0.032848928\n",
      "Cost on iteration 4500 : 0.032025985\n",
      "Cost on iteration 4600 : 0.031217461\n",
      "Cost on iteration 4700 : 0.031289514\n",
      "Cost on iteration 4800 : 0.03146583\n",
      "Cost on iteration 4900 : 0.031565297\n",
      "Cost on iteration 5000 : 0.030851524\n",
      "Cost on iteration 5100 : 0.03156581\n",
      "Cost on iteration 5200 : 0.02983525\n",
      "Cost on iteration 5300 : 0.030522777\n",
      "Cost on iteration 5400 : 0.03040739\n",
      "Cost on iteration 5500 : 0.029402768\n",
      "Cost on iteration 5600 : 0.030715287\n",
      "Cost on iteration 5700 : 0.029828832\n",
      "Cost on iteration 5800 : 0.029503066\n",
      "Cost on iteration 5900 : 0.03077735\n",
      "Cost on iteration 6000 : 0.029308481\n",
      "Cost on iteration 6100 : 0.031044045\n",
      "Cost on iteration 6200 : 0.029660108\n",
      "Cost on iteration 6300 : 0.029478028\n",
      "Cost on iteration 6400 : 0.029574793\n",
      "Cost on iteration 6500 : 0.029246004\n",
      "Cost on iteration 6600 : 0.02935388\n",
      "Cost on iteration 6700 : 0.028813422\n",
      "Cost on iteration 6800 : 0.02933647\n",
      "Cost on iteration 6900 : 0.028419498\n",
      "Cost on iteration 7000 : 0.029142456\n",
      "Cost on iteration 7100 : 0.029674064\n",
      "Cost on iteration 7200 : 0.028321262\n",
      "Cost on iteration 7300 : 0.028513735\n",
      "Cost on iteration 7400 : 0.029589111\n",
      "Cost on iteration 7500 : 0.029522752\n",
      "Cost on iteration 7600 : 0.028915053\n",
      "Cost on iteration 7700 : 0.02824568\n",
      "Cost on iteration 7800 : 0.028807977\n",
      "Cost on iteration 7900 : 0.028799662\n",
      "Cost on iteration 8000 : 0.02951615\n",
      "Cost on iteration 8100 : 0.028250176\n",
      "Cost on iteration 8200 : 0.028245699\n",
      "Cost on iteration 8300 : 0.028175138\n",
      "Cost on iteration 8400 : 0.028303152\n",
      "Cost on iteration 8500 : 0.028110392\n",
      "Cost on iteration 8600 : 0.028766954\n",
      "Cost on iteration 8700 : 0.028227013\n",
      "Cost on iteration 8800 : 0.034048017\n",
      "Cost on iteration 8900 : 0.0347907\n",
      "Cost on iteration 9000 : 0.03459015\n",
      "Cost on iteration 9100 : 0.03330975\n",
      "Cost on iteration 9200 : 0.03351059\n",
      "Cost on iteration 9300 : 0.033020876\n",
      "Cost on iteration 9400 : 0.032701474\n",
      "Cost on iteration 9500 : 0.033025406\n",
      "Cost on iteration 9600 : 0.0322564\n",
      "Cost on iteration 9700 : 0.03128502\n",
      "Cost on iteration 9800 : 0.031975254\n",
      "Cost on iteration 9900 : 0.03179664\n"
     ]
    }
   ],
   "source": [
    "network.train(X_train, Y_train, learning_rate, iterations, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error on train set:  0.03204111\n",
      "Average error on test set:  0.04807446\n",
      "***********************\n",
      "predictions:  [[0.03624222]\n",
      " [0.04445216]\n",
      " [0.18516344]\n",
      " ...\n",
      " [0.0870213 ]\n",
      " [0.03662466]\n",
      " [0.17077722]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train=network.predict(X_train)\n",
    "error_train=network.evaluate_rmse(predictions_train,Y_train).eval()\n",
    "\n",
    "predictions_test=network.predict(X_test)\n",
    "error_test=network.evaluate_rmse(predictions_test,Y_test).eval()\n",
    "\n",
    "predictions_test=predictions_test.eval()\n",
    "    \n",
    "print(\"Average error on train set: \", error_train)\n",
    "print(\"Average error on test set: \", error_test)\n",
    "\n",
    "print(\"***********************\")\n",
    "print(\"predictions: \", predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#чтобы сохранить модель\n",
    "#saver.save(sess, 'saved models/addfolder/addfilename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(array of predictions).to_csv(\"file path\", header=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
