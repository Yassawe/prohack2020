{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, hidden_layers,dropout):\n",
    "        hidden_layers.insert(0,77)\n",
    "        hidden_layers.append(1)\n",
    "        self.layers=hidden_layers\n",
    "        self.L=len(hidden_layers)\n",
    "        print(self.L)\n",
    "        \n",
    "        #self.beta={}\n",
    "        #self.gamma={}\n",
    "        self.W={}\n",
    "        self.b={}\n",
    "        \n",
    "        self.keepprob={}\n",
    "        \n",
    "        #self.dbeta={}\n",
    "        #self.dgamma={}\n",
    "        self.dW={}\n",
    "        self.db={}\n",
    "        self.initialize_parameters(dropout)\n",
    "        \n",
    "    def initialize_parameters(self, dropout):\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            #self.beta[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            #self.gamma[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            self.keepprob[i]=tf.Variable(dropout)\n",
    "            \n",
    "    def forward_pass(self,A, mode=\"train\"):\n",
    "        for i in range(1, self.L):\n",
    "            if mode==\"train\":\n",
    "                A = tf.nn.dropout(A, self.keepprob[i])\n",
    "            Z=tf.matmul(self.W[i],A)+self.b[i]\n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "            else:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self,Yhat,Y):\n",
    "        cost=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Yhat, Y))) #root mean square error cost function\n",
    "        return cost\n",
    "    \n",
    "    def evaluate_rmse(self, predicted, Y):\n",
    "        rmse=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(predicted, Y))) #root mean square error cost function\n",
    "        return rmse\n",
    "    \n",
    "    def update_parameters(self,learning_rate, normalization_lr):\n",
    "            for i in range(1,self.L):\n",
    "                self.W[i].assign_sub(learning_rate*self.dW[i])\n",
    "                self.b[i].assign_sub(learning_rate*self.db[i])\n",
    "                #self.beta[i].assign_sub(normalization_lr*self.dbeta[i])\n",
    "                #self.gamma[i].assign_sub(normalization_lr*self.dgamma[i])\n",
    "    \n",
    "    def train(self,X,Y, learning_rate, decay_rate, normalization_lr, iterations):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        Y=tf.convert_to_tensor(Y, dtype=tf.float32)\n",
    "        for i in range(iterations+1):\n",
    "            with tf.GradientTape(persistent=True) as g:\n",
    "                Yhat=self.forward_pass(X)\n",
    "                cost=self.compute_cost(Yhat,Y)\n",
    "                \n",
    "            for j in range(1,self.L):\n",
    "                self.dW[j]=g.gradient(cost, self.W[j])\n",
    "                self.db[j]=g.gradient(cost, self.b[j])\n",
    "                #self.dbeta[j]=g.gradient(cost, self.beta[j])\n",
    "                #self.dgamma[j]=g.gradient(cost,self.gamma[j])\n",
    "                \n",
    "            del g\n",
    "            \n",
    "            learning_rate=learning_rate/(1+decay_rate*i)\n",
    "            \n",
    "            self.update_parameters(learning_rate, normalization_lr)\n",
    "            if (i%100==0):\n",
    "                print(\"Error on iteration {} is: \".format(i), cost.numpy())\n",
    "    \n",
    "    def upload_parameters(self,W,b,beta,gamma):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.beta=beta\n",
    "        self.gamma=gamma\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        prediction=self.forward_pass(X, mode=\"test\")\n",
    "        return prediction\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 2532)\n",
      "(1, 2532)\n",
      "(77, 1333)\n",
      "(1, 1333)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('norm_negignore_knn3+mean/x_train_knn+mean.csv', header=0).values[:, 1:].T\n",
    "Y_train = pd.read_csv('norm_negignore_knn3+mean/y_train_knn+mean.csv', header=0).values[:, 1:].T\n",
    "X_test = pd.read_csv('norm_negignore_knn3+mean/x_test_knn+mean.csv', header=0).values[:, 1:].T\n",
    "Y_test = pd.read_csv('norm_negignore_knn3+mean/y_test_knn+mean.csv', header=0).values[:, 1:].T\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#цифры на шару\n",
    "hidden_layers=[128,320,320,20] #кол-во элементов это кол-во hidden layers, значение элемента это кол-во neurons в этом layer\n",
    "learning_rate=0.001\n",
    "decay_rate=0.001\n",
    "dropout=0.6\n",
    "normalization_lr=0.001\n",
    "\n",
    "iterations=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "network=NN(hidden_layers,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on iteration 0 is:  0.8260218\n",
      "Error on iteration 100 is:  0.822001\n",
      "Error on iteration 200 is:  0.8174021\n",
      "Error on iteration 300 is:  0.8248571\n",
      "Error on iteration 400 is:  0.82216114\n",
      "Error on iteration 500 is:  0.8269233\n",
      "Error on iteration 600 is:  0.8218527\n",
      "Error on iteration 700 is:  0.8235209\n",
      "Error on iteration 800 is:  0.8299045\n",
      "Error on iteration 900 is:  0.82232\n",
      "Error on iteration 1000 is:  0.82989854\n",
      "Error on iteration 1100 is:  0.82800454\n",
      "Error on iteration 1200 is:  0.82098794\n",
      "Error on iteration 1300 is:  0.8287737\n",
      "Error on iteration 1400 is:  0.8171626\n"
     ]
    }
   ],
   "source": [
    "network.train(X_train, Y_train, learning_rate, decay_rate, normalization_lr, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error on train set:  0.06429713\n",
      "Average error on test set:  0.06168457\n"
     ]
    }
   ],
   "source": [
    "predictions_train=network.predict(X_train)\n",
    "error_train=network.evaluate_rmse(predictions_train,Y_train)\n",
    "\n",
    "predictions_test=network.predict(X_test)\n",
    "error_test=network.evaluate_rmse(predictions_test,Y_test)\n",
    "\n",
    "print(\"Average error on train set: \", error_train.numpy())\n",
    "print(\"Average error on test set: \", error_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.7752468   0.69046414  2.1087976  -0.03039051 -0.89051473]\n",
      " [-0.0836528  -1.0781559   0.15010412  0.2678005   0.7609479 ]\n",
      " [ 0.8181854  -0.6325146   0.4490876   1.7830693  -0.18869902]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.30840796  0.2746798   0.8389199  -0.01208992 -0.35426375]\n",
      " [-0.06162434 -0.79424286  0.11057689  0.19728005  0.5605659 ]\n",
      " [ 0.38629228 -0.29863098  0.21202905  0.84184575 -0.08909103]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2.5137055]\n",
      " [1.3574637]\n",
      " [2.1180475]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.Variable(tf.random.normal(shape=(3,5)))\n",
    "a=tf.convert_to_tensor(a, dtype=tf.float32)\n",
    "print(a)\n",
    "a, norm=tf.linalg.normalize(a, axis=1)\n",
    "print(a)\n",
    "print(norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
