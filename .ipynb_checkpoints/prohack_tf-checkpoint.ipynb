{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yassawe\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, hidden_layers):\n",
    "        hidden_layers.insert(0,77)\n",
    "        hidden_layers.append(1)\n",
    "        self.layers=hidden_layers\n",
    "        self.L=len(hidden_layers)\n",
    "        #self.beta={}\n",
    "        #self.gamma={}\n",
    "        self.W={}\n",
    "        self.b={}\n",
    "        self.keepprob={}\n",
    "        self.initialize_parameters()\n",
    "     \n",
    "    def placeholders(self):\n",
    "        X=tf.placeholder(tf.float32, shape=(None, 77), name=\"X\")\n",
    "        Y=tf.placeholder(tf.float32, shape=(None, 1), name=\"Y\")\n",
    "        return X,Y\n",
    "    \n",
    "    def initialize_parameters(self):\n",
    "        for i in range(1, self.L):\n",
    "            self.W[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],self.layers[i-1])))\n",
    "            self.b[i]=tf.Variable(tf.random.normal(shape=(self.layers[i],1)))\n",
    "            self.keepprob[i]=tf.Variable(0.8)\n",
    "            #self.beta[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            #self.gamma[i]=tf.Variable(tf.random.normal(shape=(1,1)))\n",
    "            \n",
    "    def forward_pass(self,A, mode=\"train\"):\n",
    "        for i in range(1, self.L):\n",
    "            if mode==\"train\":\n",
    "                A = tf.nn.dropout(A, self.keepprob[i]) \n",
    "            \n",
    "            Z = tf.matmul(A,tf.transpose(self.W[i]))+tf.transpose(self.b[i])\n",
    "            \n",
    "            if i!=self.L-1:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "            else:\n",
    "                A=tf.nn.sigmoid(Z)\n",
    "        return A\n",
    "    \n",
    "    def compute_cost(self,Yhat,Y):\n",
    "        cost=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(Yhat, Y)))\n",
    "        return cost\n",
    "    \n",
    "    def evaluate_rmse(self, predicted, Y):\n",
    "        rmse=tf.sqrt(tf.reduce_mean(tf.math.squared_difference(predicted, Y))) #root mean square error cost function\n",
    "        return rmse\n",
    "    \n",
    "    def train(self, X_train,Y_train, learning_rate, iterations, sess):\n",
    "        X,Y=self.placeholders()\n",
    "        Yhat=self.forward_pass(X)\n",
    "        cost=self.compute_cost(Yhat, Y)\n",
    "        \n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        decayed_lr = tf.train.exponential_decay(learning_rate, global_step, 1000, 0.5, staircase=True)\n",
    "        trainer = tf.train.AdamOptimizer(decayed_lr, epsilon=1e-10).minimize(cost)\n",
    "        init=tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for i in range(iterations):\n",
    "            _ ,temp_cost=sess.run([trainer, cost], feed_dict={X:X_train, Y:Y_train})\n",
    "            if i%100==0:\n",
    "                print(\"Cost on iteration {} :\".format(i), temp_cost)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X=tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        prediction=self.forward_pass(X, \"test\")\n",
    "        return prediction\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2532, 77)\n",
      "(2532, 1)\n",
      "(1333, 77)\n",
      "(1333, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#первый датасет Доры\n",
    "X_train = pd.read_csv('nonorm_negignore_knn3/x_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('nonorm_negignore_knn3/y_knn_train_negative.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('nonorm_negignore_knn3/x_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('nonorm_negignore_knn3/y_knn_test_negative.csv', header=0).values[:, 1:]\n",
    "\n",
    "#второй датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3/x_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3/y_knn_train_negative_normalized.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3/x_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3/y_knn_test_negative_normalized.csv', header=0).values[:, 1:]\n",
    "\n",
    "#третий датасет Доры\n",
    "X_train = pd.read_csv('norm_negignore_knn3+mean/x_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_knn3+mean/y_train_knn+mean.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_knn3+mean/x_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_knn3+mean/y_test_knn+mean.csv', header=0).values[:, 1:]\n",
    "\"\"\"\n",
    "#интерполяция + knn\n",
    "X_train = pd.read_csv('norm_negignore_interpol_knn3/x_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_train = pd.read_csv('norm_negignore_interpol_knn3/y_train_knn+interpol.csv', header=0).values[:, 1:]\n",
    "X_test = pd.read_csv('norm_negignore_interpol_knn3/x_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "Y_test = pd.read_csv('norm_negignore_interpol_knn3/y_test_knn+interpol.csv', header=0).values[:, 1:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers=[128,320,320,50,20] #кол-во элементов это кол-во hidden layers, значение элемента это кол-во neurons в этом layer\n",
    "learning_rate=0.001\n",
    "iterations=20000\n",
    "dropout=0.9 #probability to keep nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "network=NN(hidden_layers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "#чтобы вытащить модель из сохранения\n",
    "#saver.restore(sess, 'prohack_tf_savedmodel/saved_variable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-08ba99bd7b3c>:30: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Cost on iteration 0 : 0.575155\n",
      "Cost on iteration 100 : 0.09153306\n",
      "Cost on iteration 200 : 0.081047945\n",
      "Cost on iteration 300 : 0.06901868\n",
      "Cost on iteration 400 : 0.06377398\n",
      "Cost on iteration 500 : 0.055516284\n",
      "Cost on iteration 600 : 0.047362838\n",
      "Cost on iteration 700 : 0.04483726\n",
      "Cost on iteration 800 : 0.04157972\n",
      "Cost on iteration 900 : 0.03977648\n",
      "Cost on iteration 1000 : 0.037094075\n",
      "Cost on iteration 1100 : 0.034417603\n",
      "Cost on iteration 1200 : 0.032179788\n",
      "Cost on iteration 1300 : 0.029565798\n",
      "Cost on iteration 1400 : 0.025710274\n",
      "Cost on iteration 1500 : 0.021453416\n",
      "Cost on iteration 1600 : 0.020977644\n",
      "Cost on iteration 1700 : 0.019454276\n",
      "Cost on iteration 1800 : 0.018519372\n",
      "Cost on iteration 1900 : 0.01904484\n",
      "Cost on iteration 2000 : 0.018372327\n",
      "Cost on iteration 2100 : 0.017928243\n",
      "Cost on iteration 2200 : 0.015805546\n",
      "Cost on iteration 2300 : 0.016159967\n",
      "Cost on iteration 2400 : 0.01564264\n",
      "Cost on iteration 2500 : 0.015129217\n",
      "Cost on iteration 2600 : 0.017297968\n",
      "Cost on iteration 2700 : 0.012578562\n",
      "Cost on iteration 2800 : 0.016658196\n",
      "Cost on iteration 2900 : 0.011793717\n",
      "Cost on iteration 3000 : 0.01514314\n",
      "Cost on iteration 3100 : 0.012537169\n",
      "Cost on iteration 3200 : 0.012234868\n",
      "Cost on iteration 3300 : 0.0115170535\n",
      "Cost on iteration 3400 : 0.0113126505\n",
      "Cost on iteration 3500 : 0.011617007\n",
      "Cost on iteration 3600 : 0.011892293\n",
      "Cost on iteration 3700 : 0.012930395\n",
      "Cost on iteration 3800 : 0.008910671\n",
      "Cost on iteration 3900 : 0.012619143\n",
      "Cost on iteration 4000 : 0.010734661\n",
      "Cost on iteration 4100 : 0.008723547\n",
      "Cost on iteration 4200 : 0.008159639\n",
      "Cost on iteration 4300 : 0.008905992\n",
      "Cost on iteration 4400 : 0.010442912\n",
      "Cost on iteration 4500 : 0.007986051\n",
      "Cost on iteration 4600 : 0.012687375\n",
      "Cost on iteration 4700 : 0.00850419\n",
      "Cost on iteration 4800 : 0.00850641\n",
      "Cost on iteration 4900 : 0.00834067\n",
      "Cost on iteration 5000 : 0.0070550367\n",
      "Cost on iteration 5100 : 0.006973042\n",
      "Cost on iteration 5200 : 0.008386584\n",
      "Cost on iteration 5300 : 0.0061360556\n",
      "Cost on iteration 5400 : 0.0060474686\n",
      "Cost on iteration 5500 : 0.006199511\n",
      "Cost on iteration 5600 : 0.00827437\n",
      "Cost on iteration 5700 : 0.006801941\n",
      "Cost on iteration 5800 : 0.0047873855\n",
      "Cost on iteration 5900 : 0.003988987\n",
      "Cost on iteration 6000 : 0.0053535583\n",
      "Cost on iteration 6100 : 0.004449097\n",
      "Cost on iteration 6200 : 0.006829632\n",
      "Cost on iteration 6300 : 0.005459413\n",
      "Cost on iteration 6400 : 0.0037935649\n",
      "Cost on iteration 6500 : 0.0060323984\n",
      "Cost on iteration 6600 : 0.0046157767\n",
      "Cost on iteration 6700 : 0.0036416168\n",
      "Cost on iteration 6800 : 0.005492284\n",
      "Cost on iteration 6900 : 0.0035442798\n",
      "Cost on iteration 7000 : 0.0022690252\n",
      "Cost on iteration 7100 : 0.0039226334\n",
      "Cost on iteration 7200 : 0.004437648\n",
      "Cost on iteration 7300 : 0.0032337564\n",
      "Cost on iteration 7400 : 0.002656686\n",
      "Cost on iteration 7500 : 0.0036760385\n",
      "Cost on iteration 7600 : 0.002419085\n",
      "Cost on iteration 7700 : 0.0032805766\n",
      "Cost on iteration 7800 : 0.0022477491\n",
      "Cost on iteration 7900 : 0.004136911\n",
      "Cost on iteration 8000 : 0.0030508845\n",
      "Cost on iteration 8100 : 0.0019504022\n",
      "Cost on iteration 8200 : 0.004719542\n",
      "Cost on iteration 8300 : 0.004106436\n",
      "Cost on iteration 8400 : 0.0029118108\n",
      "Cost on iteration 8500 : 0.0023720188\n",
      "Cost on iteration 8600 : 0.002567972\n",
      "Cost on iteration 8700 : 0.0026489233\n",
      "Cost on iteration 8800 : 0.0021919217\n",
      "Cost on iteration 8900 : 0.004155437\n",
      "Cost on iteration 9000 : 0.004496198\n",
      "Cost on iteration 9100 : 0.0021687236\n",
      "Cost on iteration 9200 : 0.0021649573\n",
      "Cost on iteration 9300 : 0.001917571\n",
      "Cost on iteration 9400 : 0.0019179495\n",
      "Cost on iteration 9500 : 0.004016239\n",
      "Cost on iteration 9600 : 0.0033069984\n",
      "Cost on iteration 9700 : 0.0021235293\n",
      "Cost on iteration 9800 : 0.002049699\n",
      "Cost on iteration 9900 : 0.0014783111\n",
      "Cost on iteration 10000 : 0.0025240094\n",
      "Cost on iteration 10100 : 0.0051533175\n",
      "Cost on iteration 10200 : 0.004008798\n",
      "Cost on iteration 10300 : 0.0025418007\n",
      "Cost on iteration 10400 : 0.0024412228\n",
      "Cost on iteration 10500 : 0.0020666192\n",
      "Cost on iteration 10600 : 0.001540869\n",
      "Cost on iteration 10700 : 0.0009052466\n",
      "Cost on iteration 10800 : 0.0013565295\n",
      "Cost on iteration 10900 : 0.002381458\n",
      "Cost on iteration 11000 : 0.0020594914\n",
      "Cost on iteration 11100 : 0.0018291557\n",
      "Cost on iteration 11200 : 0.0017043856\n",
      "Cost on iteration 11300 : 0.005610168\n",
      "Cost on iteration 11400 : 0.0031147897\n",
      "Cost on iteration 11500 : 0.0027027833\n",
      "Cost on iteration 11600 : 0.0019189299\n",
      "Cost on iteration 11700 : 0.0020631514\n",
      "Cost on iteration 11800 : 0.0014624373\n",
      "Cost on iteration 11900 : 0.0010516711\n",
      "Cost on iteration 12000 : 0.0011650032\n",
      "Cost on iteration 12100 : 0.0018491893\n",
      "Cost on iteration 12200 : 0.0012504281\n",
      "Cost on iteration 12300 : 0.0015284438\n",
      "Cost on iteration 12400 : 0.0012908877\n",
      "Cost on iteration 12500 : 0.0040498856\n",
      "Cost on iteration 12600 : 0.0024962863\n",
      "Cost on iteration 12700 : 0.0020158237\n",
      "Cost on iteration 12800 : 0.0013752214\n",
      "Cost on iteration 12900 : 0.0012004516\n",
      "Cost on iteration 13000 : 0.0014415435\n",
      "Cost on iteration 13100 : 0.001899389\n",
      "Cost on iteration 13200 : 0.001391936\n",
      "Cost on iteration 13300 : 0.0017042059\n",
      "Cost on iteration 13400 : 0.0011673992\n",
      "Cost on iteration 13500 : 0.0009779163\n",
      "Cost on iteration 13600 : 0.0012633472\n",
      "Cost on iteration 13700 : 0.0026237774\n",
      "Cost on iteration 13800 : 0.0014469359\n",
      "Cost on iteration 13900 : 0.0011299863\n",
      "Cost on iteration 14000 : 0.0012684835\n",
      "Cost on iteration 14100 : 0.0028352463\n",
      "Cost on iteration 14200 : 0.003210836\n",
      "Cost on iteration 14300 : 0.0031110873\n",
      "Cost on iteration 14400 : 0.004077688\n",
      "Cost on iteration 14500 : 0.0022468928\n",
      "Cost on iteration 14600 : 0.0018911413\n",
      "Cost on iteration 14700 : 0.002466278\n",
      "Cost on iteration 14800 : 0.0011261301\n",
      "Cost on iteration 14900 : 0.0012930669\n",
      "Cost on iteration 15000 : 0.00089562876\n",
      "Cost on iteration 15100 : 0.0009828871\n",
      "Cost on iteration 15200 : 0.0021347136\n",
      "Cost on iteration 15300 : 0.0027674001\n",
      "Cost on iteration 15400 : 0.0015226484\n",
      "Cost on iteration 15500 : 0.0010498638\n",
      "Cost on iteration 15600 : 0.0011385081\n",
      "Cost on iteration 15700 : 0.0009776874\n",
      "Cost on iteration 15800 : 0.0013166328\n",
      "Cost on iteration 15900 : 0.0017551703\n",
      "Cost on iteration 16000 : 0.002536794\n",
      "Cost on iteration 16100 : 0.001481762\n",
      "Cost on iteration 16200 : 0.001528659\n",
      "Cost on iteration 16300 : 0.0011596363\n",
      "Cost on iteration 16400 : 0.0008562812\n",
      "Cost on iteration 16500 : 0.0008384321\n",
      "Cost on iteration 16600 : 0.0019705752\n",
      "Cost on iteration 16700 : 0.0025976298\n",
      "Cost on iteration 16800 : 0.002107439\n",
      "Cost on iteration 16900 : 0.0024955529\n",
      "Cost on iteration 17000 : 0.0024211449\n",
      "Cost on iteration 17100 : 0.002147216\n",
      "Cost on iteration 17200 : 0.0016300643\n",
      "Cost on iteration 17300 : 0.0009710651\n",
      "Cost on iteration 17400 : 0.0015933649\n",
      "Cost on iteration 17500 : 0.000966856\n",
      "Cost on iteration 17600 : 0.0009463423\n",
      "Cost on iteration 17700 : 0.0011972684\n",
      "Cost on iteration 17800 : 0.0007578068\n",
      "Cost on iteration 17900 : 0.0007785786\n",
      "Cost on iteration 18000 : 0.00077780173\n",
      "Cost on iteration 18100 : 0.0020875938\n",
      "Cost on iteration 18200 : 0.001995748\n",
      "Cost on iteration 18300 : 0.0013661043\n",
      "Cost on iteration 18400 : 0.0011837215\n",
      "Cost on iteration 18500 : 0.0016440623\n",
      "Cost on iteration 18600 : 0.0032972049\n",
      "Cost on iteration 18700 : 0.0034440663\n",
      "Cost on iteration 18800 : 0.0033804514\n",
      "Cost on iteration 18900 : 0.0018907713\n",
      "Cost on iteration 19000 : 0.0015821262\n",
      "Cost on iteration 19100 : 0.0011767183\n",
      "Cost on iteration 19200 : 0.00086667656\n",
      "Cost on iteration 19300 : 0.0003803881\n",
      "Cost on iteration 19400 : 0.00063976826\n",
      "Cost on iteration 19500 : 0.0015374717\n",
      "Cost on iteration 19600 : 0.0014378027\n",
      "Cost on iteration 19700 : 0.002145001\n",
      "Cost on iteration 19800 : 0.002845471\n",
      "Cost on iteration 19900 : 0.0018037016\n"
     ]
    }
   ],
   "source": [
    "network.train(X_train, Y_train, learning_rate, iterations, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1333, 77)\n",
      "(1333, 1)\n"
     ]
    }
   ],
   "source": [
    "#X_test_untouched=pd.read_csv('norm_negignore_knn3+mean/datasets_before_preprocessing/orig_x_test.csv', header=0).values[:, 3:-1]\n",
    "#Y_test_untouched=pd.read_csv('norm_negignore_knn3+mean/datasets_before_preprocessing/orig_y_test.csv', header=0).values[:, 1:]\n",
    "\n",
    "#print(X_test_untouched.shape)\n",
    "#print(Y_test_untouched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error on train set:  0.008263032\n",
      "Average error on test set:  0.012101073\n",
      "***********************\n",
      "predictions:  [[0.05125505]\n",
      " [0.07981893]\n",
      " [0.04197994]\n",
      " ...\n",
      " [0.04242513]\n",
      " [0.04710975]\n",
      " [0.04246579]]\n"
     ]
    }
   ],
   "source": [
    "predictions_train=network.predict(X_train)\n",
    "error_train=network.evaluate_rmse(predictions_train,Y_train).eval()\n",
    "\n",
    "predictions_test=network.predict(X_test)\n",
    "error_test=network.evaluate_rmse(predictions_test,Y_test).eval()\n",
    "\n",
    "predictions_test=predictions_test.eval()\n",
    "    \n",
    "print(\"Average error on train set: \", error_train)\n",
    "print(\"Average error on test set: \", error_test)\n",
    "\n",
    "print(\"***********************\")\n",
    "print(\"predictions: \", predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(890, 77)\n",
      "[[0.         0.         0.08567655 ... 0.40048412 0.70137238 0.72129293]\n",
      " [0.09283368 0.11594609 0.02009468 ... 0.17935913 0.62834384 0.73637256]\n",
      " [0.13203362 0.15997091 0.19983498 ... 0.27081847 0.64374378 0.70970685]\n",
      " ...\n",
      " [0.58885002 0.58069709 0.24521578 ... 0.2000581  0.69118268 0.44697428]\n",
      " [0.58885002 0.58069709 0.24521578 ... 0.2000581  0.69118268 0.44697428]\n",
      " [0.58885002 0.58069709 0.24521578 ... 0.2000581  0.69118268 0.44697428]]\n"
     ]
    }
   ],
   "source": [
    "test_set=pd.read_csv('norm_negignore_interpol_knn3/test_cleaned.csv', header=0).values[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predict=network.predict(test_set).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prohack_tf_savedmodel_interpolation/interpolation'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#чтобы сохранить модель\n",
    "saver.save(sess, 'prohack_tf_savedmodel_interpolation/interpolation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(final_predict).to_csv(\"Y.csv\", header=[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
